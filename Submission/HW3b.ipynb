{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rob/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/rob/anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "import sklearn.linear_model\n",
    "import sklearn.svm\n",
    "\n",
    "# special matplotlib command for global plot configuration\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
    "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
    "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
    "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),            \n",
    "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
    "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
    "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843)]\n",
    "\n",
    "cmap_set1 = ListedColormap(['#e41a1c', '#377eb8', '#4daf4a'])\n",
    "dark2_cmap=ListedColormap(dark2_colors)\n",
    "\n",
    "def set_mpl_params():\n",
    "    rcParams['figure.figsize'] = (10, 6)\n",
    "    rcParams['figure.dpi'] = 150\n",
    "    rcParams['axes.prop_cycle'].by_key()['color'][1]\n",
    "    rcParams['lines.linewidth'] = 2\n",
    "    rcParams['axes.facecolor'] = 'white'\n",
    "    rcParams['font.size'] = 14\n",
    "    rcParams['patch.edgecolor'] = 'white'\n",
    "    rcParams['patch.facecolor'] = dark2_colors[0]\n",
    "    rcParams['font.family'] = 'StixGeneral'\n",
    "\n",
    "set_mpl_params()\n",
    "\n",
    "\n",
    "\n",
    "#First lets reading the dataset in\n",
    "X = pd.read_csv(\"trainingData.txt\",sep='\\t',header=None)\n",
    "Y = pd.read_csv(\"trainingTruth.txt\",sep='\\t',header=None)\n",
    "Y = np.array(Y).ravel()\n",
    "#X = X.fillna(0) ## imputing nan's as 0\n",
    "X.describe()\n",
    "\n",
    "# Read in test submission file\n",
    "X_testsub = pd.read_csv(\"testData.txt\",sep=\"\\t\",header=None)\n",
    "\n",
    "# Read in blind submission\n",
    "X_blindsub = pd.read_csv(\"blindData.txt\",sep=\"\\t\",header=None)\n",
    "X_blindsub.drop(X_blindsub.columns[len(X_blindsub.columns)-1], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running the estimators takes time \n",
    "# set to true to run the code\n",
    "# set to false and the output from the previous run will printed\n",
    "runEstimators = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data (3).\n",
      "Preprocessing data (3).\n",
      "Preprocessing data (3).\n"
     ]
    }
   ],
   "source": [
    "def preprocessFeatures3( X ):\n",
    "    print('Preprocessing data (3).')\n",
    "\n",
    "    # Q: Should we take a log of the data?\n",
    "    \n",
    "    # Replace any NaN in X with the mean of the column\n",
    "    # Replacing with the mean gives a better score\n",
    "    xMean = []\n",
    "    for col in X.columns:\n",
    "        xMean = X[col].mean()\n",
    "        #print(col, ' ', xMean)\n",
    "        X.loc[X[col].isnull(), col] = xMean\n",
    "    \n",
    "\n",
    "    \n",
    "    # Lets normalize the data to accomodate those classification methods \n",
    "    #  that can benefit from it (e.g. SVM)\n",
    "    #X = (X - X.mean(axis=0)) /  X.std(axis=0)\n",
    "    \n",
    "    return (X)\n",
    "\n",
    "\n",
    "def removeNans(X):\n",
    "    #print(X.isnull())\n",
    "    inds = X.isnull().any()\n",
    "    print('Nans ', inds)\n",
    "    \n",
    "    X2 = X[inds]\n",
    "    print(X.shape)\n",
    "    print(X2.shape)\n",
    "    #X = X.dropna()\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "X = preprocessFeatures3( X )\n",
    "X_testsub = preprocessFeatures3( X_testsub )\n",
    "X_blindsub = preprocessFeatures3( X_blindsub )\n",
    "\n",
    "# Normalize all data to mean 0 and SD of 1\n",
    "std_scale = StandardScaler().fit(X_testsub)\n",
    "X_testsub = std_scale.transform(X_testsub)\n",
    "\n",
    "std_scale = StandardScaler().fit(X_blindsub)\n",
    "X_blindsub = std_scale.transform(X_blindsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17378, 334)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>324</th>\n",
       "      <th>325</th>\n",
       "      <th>326</th>\n",
       "      <th>327</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6343</td>\n",
       "      <td>0.3623</td>\n",
       "      <td>0.435167</td>\n",
       "      <td>0.4771</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>0.9309</td>\n",
       "      <td>0.3619</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7431</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>0.1783</td>\n",
       "      <td>-0.7218</td>\n",
       "      <td>1.0397</td>\n",
       "      <td>0.3064</td>\n",
       "      <td>-0.1804</td>\n",
       "      <td>0.5108</td>\n",
       "      <td>-0.7427</td>\n",
       "      <td>0.7402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.1128</td>\n",
       "      <td>0.2567</td>\n",
       "      <td>-0.315000</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.1011</td>\n",
       "      <td>0.5484</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6729</td>\n",
       "      <td>0.6554</td>\n",
       "      <td>-0.0108</td>\n",
       "      <td>-0.1236</td>\n",
       "      <td>-0.2452</td>\n",
       "      <td>-0.0694</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.7555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.1147</td>\n",
       "      <td>-0.2147</td>\n",
       "      <td>1.079600</td>\n",
       "      <td>0.6069</td>\n",
       "      <td>0.3323</td>\n",
       "      <td>0.8456</td>\n",
       "      <td>0.3082</td>\n",
       "      <td>0.7404</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.3531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1409</td>\n",
       "      <td>-0.0531</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>-0.3720</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>0.2841</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.1393</td>\n",
       "      <td>0.3778</td>\n",
       "      <td>0.666700</td>\n",
       "      <td>1.1136</td>\n",
       "      <td>0.6970</td>\n",
       "      <td>-1.0491</td>\n",
       "      <td>0.1121</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>-0.4056</td>\n",
       "      <td>-0.4072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3824</td>\n",
       "      <td>1.0743</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>0.4585</td>\n",
       "      <td>-0.3990</td>\n",
       "      <td>0.5170</td>\n",
       "      <td>-0.0985</td>\n",
       "      <td>0.7276</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>-0.2179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.1739</td>\n",
       "      <td>-0.2137</td>\n",
       "      <td>0.411800</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.4143</td>\n",
       "      <td>-0.0570</td>\n",
       "      <td>0.6324</td>\n",
       "      <td>1.0733</td>\n",
       "      <td>-0.4641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2810</td>\n",
       "      <td>-0.0898</td>\n",
       "      <td>-0.2685</td>\n",
       "      <td>0.8918</td>\n",
       "      <td>-0.3160</td>\n",
       "      <td>0.4253</td>\n",
       "      <td>-0.3345</td>\n",
       "      <td>-0.0639</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>0.2293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0       1         2       3       4       5       6       7       8    \\\n",
       "0  0.6343  0.3623  0.435167  0.4771  0.1597  0.2117  0.9309  0.3619  0.5584   \n",
       "1 -0.1128  0.2567 -0.315000  0.0312  0.4733  0.1741  0.1306  0.1011  0.5484   \n",
       "2 -0.1147 -0.2147  1.079600  0.6069  0.3323  0.8456  0.3082  0.7404  0.1146   \n",
       "3 -0.1393  0.3778  0.666700  1.1136  0.6970 -1.0491  0.1121  0.8550 -0.4056   \n",
       "4 -0.1739 -0.2137  0.411800  0.2800  0.1626  0.4143 -0.0570  0.6324  1.0733   \n",
       "\n",
       "      9     ...       324     325     326     327     328     329     330  \\\n",
       "0  0.1471   ...    0.7431  0.3330  0.1783 -0.7218  1.0397  0.3064 -0.1804   \n",
       "1  0.1618   ...    0.6729  0.6554 -0.0108 -0.1236 -0.2452 -0.0694  0.1850   \n",
       "2  0.3531   ...   -0.1409 -0.0531  0.0121  0.7682  0.5060 -0.3720  0.0644   \n",
       "3 -0.4072   ...    0.3824  1.0743  0.1053  0.4585 -0.3990  0.5170 -0.0985   \n",
       "4 -0.4641   ...    0.2810 -0.0898 -0.2685  0.8918 -0.3160  0.4253 -0.3345   \n",
       "\n",
       "      331     332     333  \n",
       "0  0.5108 -0.7427  0.7402  \n",
       "1  0.9860  0.6855  0.7555  \n",
       "2  0.2841  0.0834  0.1460  \n",
       "3  0.7276  0.0813 -0.2179  \n",
       "4 -0.0639  0.2184  0.2293  \n",
       "\n",
       "[5 rows x 334 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>324</th>\n",
       "      <th>325</th>\n",
       "      <th>326</th>\n",
       "      <th>327</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17373</th>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>-0.6586</td>\n",
       "      <td>-0.0810</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>-0.1383</td>\n",
       "      <td>0.1966</td>\n",
       "      <td>0.4916</td>\n",
       "      <td>-0.1731</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2738</td>\n",
       "      <td>-0.6897</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0796</td>\n",
       "      <td>-0.2519</td>\n",
       "      <td>0.447165</td>\n",
       "      <td>1.1893</td>\n",
       "      <td>0.6007</td>\n",
       "      <td>0.8424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>0.4840</td>\n",
       "      <td>1.0259</td>\n",
       "      <td>0.6091</td>\n",
       "      <td>0.4844</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.9806</td>\n",
       "      <td>0.3355</td>\n",
       "      <td>-0.5224</td>\n",
       "      <td>1.3731</td>\n",
       "      <td>0.2330</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2168</td>\n",
       "      <td>1.5069</td>\n",
       "      <td>0.2802</td>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.4491</td>\n",
       "      <td>1.0596</td>\n",
       "      <td>-0.285200</td>\n",
       "      <td>-0.4714</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>0.3336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>0.3170</td>\n",
       "      <td>0.4889</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.8180</td>\n",
       "      <td>1.2458</td>\n",
       "      <td>-0.2427</td>\n",
       "      <td>0.3136</td>\n",
       "      <td>0.3064</td>\n",
       "      <td>0.8588</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>1.1703</td>\n",
       "      <td>-0.3599</td>\n",
       "      <td>-0.6184</td>\n",
       "      <td>0.6256</td>\n",
       "      <td>0.5277</td>\n",
       "      <td>0.220200</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.4387</td>\n",
       "      <td>0.2579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>-0.1188</td>\n",
       "      <td>0.8574</td>\n",
       "      <td>-0.0358</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>-0.1764</td>\n",
       "      <td>0.6991</td>\n",
       "      <td>0.5083</td>\n",
       "      <td>-0.1800</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2942</td>\n",
       "      <td>0.4487</td>\n",
       "      <td>-0.1378</td>\n",
       "      <td>0.7742</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>-0.2275</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>0.2092</td>\n",
       "      <td>0.4246</td>\n",
       "      <td>0.7770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>-0.3133</td>\n",
       "      <td>0.7629</td>\n",
       "      <td>0.4839</td>\n",
       "      <td>0.5712</td>\n",
       "      <td>-0.4183</td>\n",
       "      <td>0.5916</td>\n",
       "      <td>0.9065</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.7223</td>\n",
       "      <td>1.0139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4759</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>0.3312</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>1.628200</td>\n",
       "      <td>0.8187</td>\n",
       "      <td>-0.5652</td>\n",
       "      <td>0.4126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1       2       3       4       5       6       7       8    \\\n",
       "17373  0.3250  0.9640 -0.6586 -0.0810  0.8684 -0.1383  0.1966  0.4916 -0.1731   \n",
       "17374  0.4840  1.0259  0.6091  0.4844  0.8739  0.9806  0.3355 -0.5224  1.3731   \n",
       "17375  0.3170  0.4889  0.1417  0.8180  1.2458 -0.2427  0.3136  0.3064  0.8588   \n",
       "17376 -0.1188  0.8574 -0.0358  0.4499  0.9471 -0.1764  0.6991  0.5083 -0.1800   \n",
       "17377 -0.3133  0.7629  0.4839  0.5712 -0.4183  0.5916  0.9065  0.1442  0.7223   \n",
       "\n",
       "          9     ...       324     325     326     327     328     329  \\\n",
       "17373  0.3044   ...    0.2738 -0.6897  0.2765  0.1040  0.0796 -0.2519   \n",
       "17374  0.2330   ...    1.2168  1.5069  0.2802  0.6469  0.4491  1.0596   \n",
       "17375  0.6000   ...    0.0735  1.1703 -0.3599 -0.6184  0.6256  0.5277   \n",
       "17376  0.6998   ...    0.2942  0.4487 -0.1378  0.7742  0.0397 -0.2275   \n",
       "17377  1.0139   ...    0.4759  0.3724  0.3312  0.7245  0.7625  0.8673   \n",
       "\n",
       "            330     331     332     333  \n",
       "17373  0.447165  1.1893  0.6007  0.8424  \n",
       "17374 -0.285200 -0.4714  0.6295  0.3336  \n",
       "17375  0.220200  0.2174  0.4387  0.2579  \n",
       "17376  0.757000  0.2092  0.4246  0.7770  \n",
       "17377  1.628200  0.8187 -0.5652  0.4126  \n",
       "\n",
       "[5 rows x 334 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>324</th>\n",
       "      <th>325</th>\n",
       "      <th>326</th>\n",
       "      <th>327</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.264572</td>\n",
       "      <td>0.456596</td>\n",
       "      <td>0.435167</td>\n",
       "      <td>0.263299</td>\n",
       "      <td>0.496509</td>\n",
       "      <td>0.356921</td>\n",
       "      <td>0.362990</td>\n",
       "      <td>0.275144</td>\n",
       "      <td>0.423023</td>\n",
       "      <td>0.454524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448383</td>\n",
       "      <td>0.481281</td>\n",
       "      <td>0.277807</td>\n",
       "      <td>0.333366</td>\n",
       "      <td>0.474403</td>\n",
       "      <td>0.273570</td>\n",
       "      <td>0.447165</td>\n",
       "      <td>0.487169</td>\n",
       "      <td>0.267626</td>\n",
       "      <td>0.389999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.455194</td>\n",
       "      <td>0.512302</td>\n",
       "      <td>0.508479</td>\n",
       "      <td>0.451345</td>\n",
       "      <td>0.512481</td>\n",
       "      <td>0.494936</td>\n",
       "      <td>0.497232</td>\n",
       "      <td>0.463225</td>\n",
       "      <td>0.502766</td>\n",
       "      <td>0.512201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511349</td>\n",
       "      <td>0.519878</td>\n",
       "      <td>0.459788</td>\n",
       "      <td>0.484340</td>\n",
       "      <td>0.517393</td>\n",
       "      <td>0.459233</td>\n",
       "      <td>0.512634</td>\n",
       "      <td>0.511158</td>\n",
       "      <td>0.455598</td>\n",
       "      <td>0.503117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.560800</td>\n",
       "      <td>-1.506400</td>\n",
       "      <td>-1.399000</td>\n",
       "      <td>-1.488200</td>\n",
       "      <td>-1.442100</td>\n",
       "      <td>-1.306400</td>\n",
       "      <td>-1.884400</td>\n",
       "      <td>-1.721200</td>\n",
       "      <td>-1.444100</td>\n",
       "      <td>-1.578400</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.448600</td>\n",
       "      <td>-1.398600</td>\n",
       "      <td>-1.570100</td>\n",
       "      <td>-1.847300</td>\n",
       "      <td>-1.626700</td>\n",
       "      <td>-1.865800</td>\n",
       "      <td>-1.403600</td>\n",
       "      <td>-1.628900</td>\n",
       "      <td>-1.696800</td>\n",
       "      <td>-1.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.043575</td>\n",
       "      <td>0.106125</td>\n",
       "      <td>0.090225</td>\n",
       "      <td>-0.038925</td>\n",
       "      <td>0.145875</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.023125</td>\n",
       "      <td>-0.033900</td>\n",
       "      <td>0.084350</td>\n",
       "      <td>0.098025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>0.127750</td>\n",
       "      <td>-0.029200</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.109625</td>\n",
       "      <td>-0.038300</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>-0.039325</td>\n",
       "      <td>0.044350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.263900</td>\n",
       "      <td>0.453700</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.263299</td>\n",
       "      <td>0.497400</td>\n",
       "      <td>0.349400</td>\n",
       "      <td>0.354650</td>\n",
       "      <td>0.275144</td>\n",
       "      <td>0.417850</td>\n",
       "      <td>0.451100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444400</td>\n",
       "      <td>0.481281</td>\n",
       "      <td>0.277807</td>\n",
       "      <td>0.320800</td>\n",
       "      <td>0.474403</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.439600</td>\n",
       "      <td>0.482100</td>\n",
       "      <td>0.265900</td>\n",
       "      <td>0.383300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.567975</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.779375</td>\n",
       "      <td>0.562600</td>\n",
       "      <td>0.844300</td>\n",
       "      <td>0.684075</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.585200</td>\n",
       "      <td>0.760375</td>\n",
       "      <td>0.802675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798675</td>\n",
       "      <td>0.836675</td>\n",
       "      <td>0.584700</td>\n",
       "      <td>0.652475</td>\n",
       "      <td>0.831375</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.793350</td>\n",
       "      <td>0.840700</td>\n",
       "      <td>0.572025</td>\n",
       "      <td>0.726225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.054600</td>\n",
       "      <td>2.519100</td>\n",
       "      <td>2.413700</td>\n",
       "      <td>2.129900</td>\n",
       "      <td>2.335800</td>\n",
       "      <td>2.251800</td>\n",
       "      <td>2.335600</td>\n",
       "      <td>2.086000</td>\n",
       "      <td>2.452100</td>\n",
       "      <td>2.486900</td>\n",
       "      <td>...</td>\n",
       "      <td>2.433600</td>\n",
       "      <td>2.372700</td>\n",
       "      <td>2.028400</td>\n",
       "      <td>2.522400</td>\n",
       "      <td>2.303300</td>\n",
       "      <td>2.020800</td>\n",
       "      <td>2.578200</td>\n",
       "      <td>2.407200</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>2.387100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  17378.000000  17378.000000  17378.000000  17378.000000  17378.000000   \n",
       "mean       0.264572      0.456596      0.435167      0.263299      0.496509   \n",
       "std        0.455194      0.512302      0.508479      0.451345      0.512481   \n",
       "min       -1.560800     -1.506400     -1.399000     -1.488200     -1.442100   \n",
       "25%       -0.043575      0.106125      0.090225     -0.038925      0.145875   \n",
       "50%        0.263900      0.453700      0.432000      0.263299      0.497400   \n",
       "75%        0.567975      0.798000      0.779375      0.562600      0.844300   \n",
       "max        2.054600      2.519100      2.413700      2.129900      2.335800   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  17378.000000  17378.000000  17378.000000  17378.000000  17378.000000   \n",
       "mean       0.356921      0.362990      0.275144      0.423023      0.454524   \n",
       "std        0.494936      0.497232      0.463225      0.502766      0.512201   \n",
       "min       -1.306400     -1.884400     -1.721200     -1.444100     -1.578400   \n",
       "25%        0.020900      0.023125     -0.033900      0.084350      0.098025   \n",
       "50%        0.349400      0.354650      0.275144      0.417850      0.451100   \n",
       "75%        0.684075      0.693100      0.585200      0.760375      0.802675   \n",
       "max        2.251800      2.335600      2.086000      2.452100      2.486900   \n",
       "\n",
       "           ...                324           325           326           327  \\\n",
       "count      ...       17378.000000  17378.000000  17378.000000  17378.000000   \n",
       "mean       ...           0.448383      0.481281      0.277807      0.333366   \n",
       "std        ...           0.511349      0.519878      0.459788      0.484340   \n",
       "min        ...          -1.448600     -1.398600     -1.570100     -1.847300   \n",
       "25%        ...           0.095100      0.127750     -0.029200      0.008125   \n",
       "50%        ...           0.444400      0.481281      0.277807      0.320800   \n",
       "75%        ...           0.798675      0.836675      0.584700      0.652475   \n",
       "max        ...           2.433600      2.372700      2.028400      2.522400   \n",
       "\n",
       "                328           329           330           331           332  \\\n",
       "count  17378.000000  17378.000000  17378.000000  17378.000000  17378.000000   \n",
       "mean       0.474403      0.273570      0.447165      0.487169      0.267626   \n",
       "std        0.517393      0.459233      0.512634      0.511158      0.455598   \n",
       "min       -1.626700     -1.865800     -1.403600     -1.628900     -1.696800   \n",
       "25%        0.109625     -0.038300      0.100400      0.134100     -0.039325   \n",
       "50%        0.474403      0.273400      0.439600      0.482100      0.265900   \n",
       "75%        0.831375      0.584375      0.793350      0.840700      0.572025   \n",
       "max        2.303300      2.020800      2.578200      2.407200      2.070000   \n",
       "\n",
       "                333  \n",
       "count  17378.000000  \n",
       "mean       0.389999  \n",
       "std        0.503117  \n",
       "min       -1.466600  \n",
       "25%        0.044350  \n",
       "50%        0.383300  \n",
       "75%        0.726225  \n",
       "max        2.387100  \n",
       "\n",
       "[8 rows x 334 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>324</th>\n",
       "      <th>325</th>\n",
       "      <th>326</th>\n",
       "      <th>327</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "      <td>17378.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.264572</td>\n",
       "      <td>0.456596</td>\n",
       "      <td>0.435167</td>\n",
       "      <td>0.263299</td>\n",
       "      <td>0.496509</td>\n",
       "      <td>0.356921</td>\n",
       "      <td>0.362990</td>\n",
       "      <td>0.275144</td>\n",
       "      <td>0.423023</td>\n",
       "      <td>0.454524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448383</td>\n",
       "      <td>0.481281</td>\n",
       "      <td>0.277807</td>\n",
       "      <td>0.333366</td>\n",
       "      <td>0.474403</td>\n",
       "      <td>0.273570</td>\n",
       "      <td>0.447165</td>\n",
       "      <td>0.487169</td>\n",
       "      <td>0.267626</td>\n",
       "      <td>0.389999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.455194</td>\n",
       "      <td>0.512302</td>\n",
       "      <td>0.508479</td>\n",
       "      <td>0.451345</td>\n",
       "      <td>0.512481</td>\n",
       "      <td>0.494936</td>\n",
       "      <td>0.497232</td>\n",
       "      <td>0.463225</td>\n",
       "      <td>0.502766</td>\n",
       "      <td>0.512201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511349</td>\n",
       "      <td>0.519878</td>\n",
       "      <td>0.459788</td>\n",
       "      <td>0.484340</td>\n",
       "      <td>0.517393</td>\n",
       "      <td>0.459233</td>\n",
       "      <td>0.512634</td>\n",
       "      <td>0.511158</td>\n",
       "      <td>0.455598</td>\n",
       "      <td>0.503117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.560800</td>\n",
       "      <td>-1.506400</td>\n",
       "      <td>-1.399000</td>\n",
       "      <td>-1.488200</td>\n",
       "      <td>-1.442100</td>\n",
       "      <td>-1.306400</td>\n",
       "      <td>-1.884400</td>\n",
       "      <td>-1.721200</td>\n",
       "      <td>-1.444100</td>\n",
       "      <td>-1.578400</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.448600</td>\n",
       "      <td>-1.398600</td>\n",
       "      <td>-1.570100</td>\n",
       "      <td>-1.847300</td>\n",
       "      <td>-1.626700</td>\n",
       "      <td>-1.865800</td>\n",
       "      <td>-1.403600</td>\n",
       "      <td>-1.628900</td>\n",
       "      <td>-1.696800</td>\n",
       "      <td>-1.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.043575</td>\n",
       "      <td>0.106125</td>\n",
       "      <td>0.090225</td>\n",
       "      <td>-0.038925</td>\n",
       "      <td>0.145875</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.023125</td>\n",
       "      <td>-0.033900</td>\n",
       "      <td>0.084350</td>\n",
       "      <td>0.098025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>0.127750</td>\n",
       "      <td>-0.029200</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.109625</td>\n",
       "      <td>-0.038300</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>-0.039325</td>\n",
       "      <td>0.044350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.263900</td>\n",
       "      <td>0.453700</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.263299</td>\n",
       "      <td>0.497400</td>\n",
       "      <td>0.349400</td>\n",
       "      <td>0.354650</td>\n",
       "      <td>0.275144</td>\n",
       "      <td>0.417850</td>\n",
       "      <td>0.451100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444400</td>\n",
       "      <td>0.481281</td>\n",
       "      <td>0.277807</td>\n",
       "      <td>0.320800</td>\n",
       "      <td>0.474403</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.439600</td>\n",
       "      <td>0.482100</td>\n",
       "      <td>0.265900</td>\n",
       "      <td>0.383300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.567975</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.779375</td>\n",
       "      <td>0.562600</td>\n",
       "      <td>0.844300</td>\n",
       "      <td>0.684075</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.585200</td>\n",
       "      <td>0.760375</td>\n",
       "      <td>0.802675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798675</td>\n",
       "      <td>0.836675</td>\n",
       "      <td>0.584700</td>\n",
       "      <td>0.652475</td>\n",
       "      <td>0.831375</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.793350</td>\n",
       "      <td>0.840700</td>\n",
       "      <td>0.572025</td>\n",
       "      <td>0.726225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.054600</td>\n",
       "      <td>2.519100</td>\n",
       "      <td>2.413700</td>\n",
       "      <td>2.129900</td>\n",
       "      <td>2.335800</td>\n",
       "      <td>2.251800</td>\n",
       "      <td>2.335600</td>\n",
       "      <td>2.086000</td>\n",
       "      <td>2.452100</td>\n",
       "      <td>2.486900</td>\n",
       "      <td>...</td>\n",
       "      <td>2.433600</td>\n",
       "      <td>2.372700</td>\n",
       "      <td>2.028400</td>\n",
       "      <td>2.522400</td>\n",
       "      <td>2.303300</td>\n",
       "      <td>2.020800</td>\n",
       "      <td>2.578200</td>\n",
       "      <td>2.407200</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>2.387100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  17378.000000  17378.000000  17378.000000  17378.000000  17378.000000   \n",
       "mean       0.264572      0.456596      0.435167      0.263299      0.496509   \n",
       "std        0.455194      0.512302      0.508479      0.451345      0.512481   \n",
       "min       -1.560800     -1.506400     -1.399000     -1.488200     -1.442100   \n",
       "25%       -0.043575      0.106125      0.090225     -0.038925      0.145875   \n",
       "50%        0.263900      0.453700      0.432000      0.263299      0.497400   \n",
       "75%        0.567975      0.798000      0.779375      0.562600      0.844300   \n",
       "max        2.054600      2.519100      2.413700      2.129900      2.335800   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  17378.000000  17378.000000  17378.000000  17378.000000  17378.000000   \n",
       "mean       0.356921      0.362990      0.275144      0.423023      0.454524   \n",
       "std        0.494936      0.497232      0.463225      0.502766      0.512201   \n",
       "min       -1.306400     -1.884400     -1.721200     -1.444100     -1.578400   \n",
       "25%        0.020900      0.023125     -0.033900      0.084350      0.098025   \n",
       "50%        0.349400      0.354650      0.275144      0.417850      0.451100   \n",
       "75%        0.684075      0.693100      0.585200      0.760375      0.802675   \n",
       "max        2.251800      2.335600      2.086000      2.452100      2.486900   \n",
       "\n",
       "           ...                324           325           326           327  \\\n",
       "count      ...       17378.000000  17378.000000  17378.000000  17378.000000   \n",
       "mean       ...           0.448383      0.481281      0.277807      0.333366   \n",
       "std        ...           0.511349      0.519878      0.459788      0.484340   \n",
       "min        ...          -1.448600     -1.398600     -1.570100     -1.847300   \n",
       "25%        ...           0.095100      0.127750     -0.029200      0.008125   \n",
       "50%        ...           0.444400      0.481281      0.277807      0.320800   \n",
       "75%        ...           0.798675      0.836675      0.584700      0.652475   \n",
       "max        ...           2.433600      2.372700      2.028400      2.522400   \n",
       "\n",
       "                328           329           330           331           332  \\\n",
       "count  17378.000000  17378.000000  17378.000000  17378.000000  17378.000000   \n",
       "mean       0.474403      0.273570      0.447165      0.487169      0.267626   \n",
       "std        0.517393      0.459233      0.512634      0.511158      0.455598   \n",
       "min       -1.626700     -1.865800     -1.403600     -1.628900     -1.696800   \n",
       "25%        0.109625     -0.038300      0.100400      0.134100     -0.039325   \n",
       "50%        0.474403      0.273400      0.439600      0.482100      0.265900   \n",
       "75%        0.831375      0.584375      0.793350      0.840700      0.572025   \n",
       "max        2.303300      2.020800      2.578200      2.407200      2.070000   \n",
       "\n",
       "                333  \n",
       "count  17378.000000  \n",
       "mean       0.389999  \n",
       "std        0.503117  \n",
       "min       -1.466600  \n",
       "25%        0.044350  \n",
       "50%        0.383300  \n",
       "75%        0.726225  \n",
       "max        2.387100  \n",
       "\n",
       "[8 rows x 334 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = (X - X.mean(axis=0)) /  X.std(axis=0)\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y1 = np.copy(Y)\n",
    "Y1[Y1!=1] = 0\n",
    "\n",
    "Y2 = np.copy(Y)\n",
    "Y2[Y2!=2] = 0\n",
    "Y2[Y2==2] = 1\n",
    "\n",
    "Y3 = np.copy(Y)\n",
    "Y3[Y3!=3] = 0\n",
    "Y3[Y3==3] = 1\n",
    "\n",
    "Y4 = np.copy(Y)\n",
    "Y4[Y4!=4] = 0\n",
    "Y4[Y4==4] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>LETS TEST WHETHER WE BINARIZED INDIVIDUAL CATEGORIES CORRECTLY:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 1, 3, 1, 4, 2, 1, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y4[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nested cross-validation. In nested cross-validation, there is an outer\n",
    "#loop over splits of the data into training and test sets. For each of them, a grid search\n",
    "#is run (which might result in different best parameters for each split in the outer\n",
    "#loop). Then, for each outer split, the test set score using the best settings is reported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>WORKING WITH THE CLASS  \"1\": Class 1 vs Rest</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17378, 334) (11643, 334) (5735, 334)\n"
     ]
    }
   ],
   "source": [
    "# As we are only provided with the \"training\" set (not taking into acount partial \"test\" data) a sensible approach to \n",
    "# compare efficiency of different models would be to hold-out some of this data for the \"testing\" purposes. \n",
    "# Because hte dataset is relatively large, we decided to leave out .33 of the data and not .50 as it is done in some scenarios\n",
    "\n",
    "# We are using train_test_split function to hold out 33% or the randomly shuffled data\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X, Y1, test_size=.33, random_state=10) \n",
    "\n",
    "print (X.shape, X_train1.shape, X_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.4924715467155387e-17"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize all data to mean 0 and SD of 1\n",
    "std_scale = StandardScaler().fit(X_train1)\n",
    "X_train1 = std_scale.transform(X_train1)\n",
    "X_test1 = std_scale.transform(X_test1)\n",
    "\n",
    "#verification of the scaling\n",
    "np.mean(X_train1[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC with RandomForest  :  0.84063237365\n",
      "AUC with GaussianNB  :  0.962701737206\n",
      "AUC with QDA  :  0.966974122135\n",
      "AUC with KNN  :  0.959179643084\n",
      "AUC with LogisticRegression  :  0.964210112601\n",
      "AUC with SVC  :  0.968478948574\n"
     ]
    }
   ],
   "source": [
    "if runEstimators:\n",
    "    estimators = [(\"RandomForest\", RandomForestClassifier(n_estimators=10,max_depth=175,min_samples_split=9,min_samples_leaf=1,random_state=1)),\n",
    "                  (\"GaussianNB\", GaussianNB()),\n",
    "                  (\"QDA\",QuadraticDiscriminantAnalysis()),\n",
    "                  (\"KNN\",KNeighborsClassifier(15, weights='distance')),\n",
    "                  (\"LogisticRegression\",LogisticRegression(random_state=57)),\n",
    "                  (\"SVC\",SVC(C = 10, gamma=0.01, kernel='rbf', probability=True))\n",
    "                 ]\n",
    "    for (name, estimator) in estimators:\n",
    "        Y_pred_test1 = estimator.fit(X_train1,Y_train1).predict_proba(X_test1)\n",
    "        #AUC\n",
    "        fpr, tpr, thresholds = roc_curve(Y_test1, Y_pred_test1[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(\"AUC with\",name, \" : \" ,roc_auc)\n",
    "else:\n",
    "    print('AUC with RandomForest  :  0.84063237365')\n",
    "    print('AUC with GaussianNB  :  0.962701737206')\n",
    "    print('AUC with QDA  :  0.966974122135')\n",
    "    print('AUC with KNN  :  0.959179643084')\n",
    "    print('AUC with LogisticRegression  :  0.964210112601')\n",
    "    print('AUC with SVC  :  0.968478948574')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>WORKING WITH THE CLASS  \"2\": Class 2 vs Rest</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17378, 334) (11643, 334) (5735, 334)\n"
     ]
    }
   ],
   "source": [
    "# As we are only provided with the \"training\" set (not taking into acount partial \"test\" data) a sensible approach to \n",
    "# compare efficiency of different models would be to hold-out some of this data for the \"testing\" purposes. \n",
    "# Because hte dataset is relatively large, we decided to leave out .33 of the data and not .50 as it is done in some scenarios\n",
    "\n",
    "# We are using train_test_split function to hold out 33% or the randomly shuffled data\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X, Y2, test_size=.33, random_state=10) \n",
    "\n",
    "print (X.shape, X_train2.shape, X_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize all data to mean 0 and SD of 1\n",
    "std_scale = StandardScaler().fit(X_train2)\n",
    "X_train2 = std_scale.transform(X_train2)\n",
    "X_test2 = std_scale.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC with RandomForest  :  0.717126395678\n",
      "AUC with GaussianNB  :  0.871723143964\n",
      "AUC with QDA  :  0.802773929661\n",
      "AUC with KNN  :  0.789426180311\n",
      "AUC with LogisticRegression  :  0.862200323207\n",
      "AUC with SVC  :  0.891752720569\n"
     ]
    }
   ],
   "source": [
    "if runEstimators:\n",
    "    estimators = [(\"RandomForest\", RandomForestClassifier(n_estimators=10,max_depth=10,min_samples_split=9,min_samples_leaf=1,random_state=1)),\n",
    "                  (\"GaussianNB\", GaussianNB()),\n",
    "                  (\"QDA\",QuadraticDiscriminantAnalysis()),\n",
    "                  (\"KNN\",KNeighborsClassifier(15, weights='distance')),\n",
    "                  (\"LogisticRegression\",LogisticRegression(random_state=57)),\n",
    "                  (\"SVC\",SVC(C=8.3, gamma=0.0035, kernel='rbf', probability=True))\n",
    "                 ]\n",
    "    for (name, estimator) in estimators:\n",
    "        Y_pred_test2 = estimator.fit(X_train2,Y_train2).predict_proba(X_test2)\n",
    "        #AUC\n",
    "        fpr, tpr, thresholds = roc_curve(Y_test2, Y_pred_test2[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(\"AUC with\",name, \" : \" ,roc_auc)\n",
    "else:\n",
    "    print('AUC with RandomForest  :  0.717126395678')\n",
    "    print('AUC with GaussianNB  :  0.871723143964')\n",
    "    print('AUC with QDA  :  0.802773929661')\n",
    "    print('AUC with KNN  :  0.789426180311')\n",
    "    print('AUC with LogisticRegression  :  0.862200323207')\n",
    "    print('AUC with SVC  :  0.891752720569')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>WORKING WITH THE CLASS  \"3\": Class 3 vs Rest</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17378, 334) (11643, 334) (5735, 334)\n"
     ]
    }
   ],
   "source": [
    "X_train3, X_test3, Y_train3, Y_test3 = train_test_split(X, Y3, test_size=.33, random_state=10) \n",
    "\n",
    "print (X.shape, X_train3.shape, X_test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize all data to mean 0 and SD of 1\n",
    "std_scale = StandardScaler().fit(X_train3)\n",
    "X_train3 = std_scale.transform(X_train3)\n",
    "X_test3 = std_scale.transform(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC with RandomForest  :  0.842445191369\n",
      "AUC with GaussianNB  :  0.958046478008\n",
      "AUC with QDA  :  0.91504109292\n",
      "AUC with KNN  :  0.938682424374\n",
      "AUC with LogisticRegression  :  0.955911525534\n",
      "AUC with SVC  :  0.962418446637\n"
     ]
    }
   ],
   "source": [
    "if runEstimators:\n",
    "    estimators = [(\"RandomForest\", RandomForestClassifier(n_estimators=10,max_depth=10,min_samples_split=9,min_samples_leaf=1,random_state=1)),\n",
    "                  (\"GaussianNB\", GaussianNB()),\n",
    "                  (\"QDA\",QuadraticDiscriminantAnalysis()),\n",
    "                  (\"KNN\",KNeighborsClassifier(15, weights='distance')),\n",
    "                  (\"LogisticRegression\",LogisticRegression(random_state=57)),\n",
    "                  (\"SVC\",SVC(C = 10, gamma=0.0033, kernel='rbf', probability=True))\n",
    "                 ]\n",
    "    for (name, estimator) in estimators:\n",
    "        Y_pred_test3 = estimator.fit(X_train3,Y_train3).predict_proba(X_test3)\n",
    "        #AUC\n",
    "        fpr, tpr, thresholds = roc_curve(Y_test3, Y_pred_test3[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(\"AUC with\",name, \" : \" ,roc_auc)\n",
    "else:\n",
    "    print('AUC with RandomForest  :  0.842445191369')\n",
    "    print('AUC with GaussianNB  :  0.958046478008')\n",
    "    print('AUC with QDA  :  0.91504109292')\n",
    "    print('AUC with KNN  :  0.938682424374')\n",
    "    print('AUC with LogisticRegression  :  0.955911525534')\n",
    "    print('AUC with SVC  :  0.962418446637')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>WORKING WITH THE CLASS  \"4\": Class 4 vs Rest</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17378, 334) (11643, 334) (5735, 334)\n"
     ]
    }
   ],
   "source": [
    "X_train4, X_test4, Y_train4, Y_test4 = train_test_split(X, Y4, test_size=.33, random_state=10) \n",
    "\n",
    "print (X.shape, X_train4.shape, X_test4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.4924715467155387e-17"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize all data to mean 0 and SD of 1\n",
    "std_scale = StandardScaler().fit(X_train4)\n",
    "X_train4 = std_scale.transform(X_train4)\n",
    "X_test4 = std_scale.transform(X_test4)\n",
    "#verification of the scaling\n",
    "np.mean(X_train4[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC with RandomForest  :  0.615432098765\n",
      "AUC with GaussianNB  :  0.811448324515\n",
      "AUC with QDA  :  0.701939329806\n",
      "AUC with KNN  :  0.704791887125\n",
      "AUC with LogisticRegression  :  0.80424526749\n",
      "AUC with SVC  :  0.829348383304\n"
     ]
    }
   ],
   "source": [
    "if runEstimators:\n",
    "    estimators = [(\"RandomForest\", RandomForestClassifier(n_estimators=10,max_depth=10,min_samples_split=9,min_samples_leaf=1,random_state=1)),\n",
    "                  (\"GaussianNB\", GaussianNB()),\n",
    "                  (\"QDA\",QuadraticDiscriminantAnalysis()),\n",
    "                  (\"KNN\",KNeighborsClassifier(15, weights='distance')),\n",
    "                  (\"LogisticRegression\",LogisticRegression(random_state=57)),\n",
    "                  (\"SVC\",SVC(C=3.4, gamma=0.01, kernel='rbf', probability=True))\n",
    "                 ]\n",
    "    for (name, estimator) in estimators:\n",
    "        Y_pred_test4 = estimator.fit(X_train4,Y_train4).predict_proba(X_test4)\n",
    "        #AUC\n",
    "        fpr, tpr, thresholds = roc_curve(Y_test4, Y_pred_test4[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(\"AUC with\",name, \" : \" ,roc_auc)\n",
    "else:\n",
    "    print('AUC with RandomForest  :  0.615432098765')\n",
    "    print('AUC with GaussianNB  :  0.811448324515')\n",
    "    print('AUC with QDA  :  0.701939329806')\n",
    "    print('AUC with KNN  :  0.704791887125')\n",
    "    print('AUC with LogisticRegression  :  0.80424526749')\n",
    "    print('AUC with SVC  :  0.829348383304')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Combining Classifiers via \"Stacking\" in order to imporove the accuracy. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Class 1 vs others</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run \"StackingAttributes.py\"\n",
    "%run \"Ensemble.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ensemble\n",
      "Running Random Forest Classifier\n",
      "Running SVM Classifier\n"
     ]
    }
   ],
   "source": [
    "attrsC1 = StackingAttributes(X_train1, Y_train1, X_test1, Y_test1, X_testsub, X_blindsub)\n",
    "\n",
    "e1 = Ensemble( attrsC1 )\n",
    "e1.run(verbose = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Class 2 vs others.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attrsC2 = StackingAttributes(X_train2, Y_train2, X_test2, Y_test2, X_testsub, X_blindsub)\n",
    "attrsC2.rf_use_rfe = True\n",
    "attrsC2.rf_n_estimators=100\n",
    "attrsC2.rf_max_depth=50\n",
    "attrsC2.rf_min_samples_split=2\n",
    "attrsC2.rf_min_samples_leaf=1\n",
    "\n",
    "attrsC2.svc_C = 10\n",
    "attrsC2.svc_gamma=0.0033\n",
    "attrsC2.svc_kernel='rbf'\n",
    "\n",
    "attrsC2.kn_n_neighbors = 500\n",
    "\n",
    "attrsC2.lr_C = 300\n",
    "\n",
    "e2 = Ensemble( attrsC2 )\n",
    "e2.run(verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Class 3 vs others.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attrsC3 = StackingAttributes(X_train3, Y_train3, X_test3, Y_test3, X_testsub, X_blindsub)\n",
    "attrsC3.rf_n_estimators=100\n",
    "attrsC3.rf_max_depth=20\n",
    "attrsC3.rf_min_samples_split=10\n",
    "attrsC3.rf_min_samples_leaf=5\n",
    "\n",
    "attrsC3.svc_C = 10\n",
    "attrsC3.svc_gamma=0.0033\n",
    "attrsC3.svc_kernel='rbf'\n",
    "\n",
    "attrsC2.kn_n_neighbors = 242\n",
    "\n",
    "attrsC3.lr_C = 0.0004\n",
    "\n",
    "\n",
    "e3 = Ensemble( attrsC3 )\n",
    "e3.run(verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Class 4 vs others.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attrsC4 = StackingAttributes(X_train4, Y_train4, X_test4, Y_test4, X_testsub, X_blindsub)\n",
    "\n",
    "attrsC4.rf_use_rfe = True\n",
    "attrsC4.rf_n_estimators=100\n",
    "attrsC4.rf_max_depth=70\n",
    "attrsC4.rf_min_samples_split=2\n",
    "attrsC4.rf_min_samples_leaf=25\n",
    "\n",
    "attrsC4.svc_C = 3.4\n",
    "attrsC4.svc_gamma=0.01\n",
    "attrsC4.svc_kernel='rbf'\n",
    "\n",
    "attrsC2.kn_n_neighbors = 925\n",
    "\n",
    "e4 = Ensemble( attrsC4 )\n",
    "e4.run(verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def submission(filename, y_final_prob):\n",
    "\n",
    "    y_final_label = np.zeros((y_final_prob.shape[0], 1), dtype=np.float)  \n",
    "\n",
    "    # Convert back to a class\n",
    "    y_final_label = np.argmax(y_final_prob, axis=1)\n",
    "    y_final_label += 1\n",
    "            \n",
    "    sample = pd.DataFrame(np.hstack([y_final_prob.round(5),y_final_label.reshape(y_final_prob.shape[0],1)]))\n",
    "    sample.columns = [\"prob1\",\"prob2\",\"prob3\",\"prob4\",\"label\"]\n",
    "    sample.label = sample.label.astype(int)\n",
    "    \n",
    "    #Submit this file to dropbox\n",
    "    sample.to_csv(filename,sep=\"\\t\" ,index=False,header=None)\n",
    "\n",
    "\n",
    "submission(\"Johnston_Memic_Test3.csv\", np.column_stack([attrsC1.final_pred_testsub[:,1],\n",
    "                                                        attrsC2.final_pred_testsub[:,1],\n",
    "                                                        attrsC3.final_pred_testsub[:,1],\n",
    "                                                        attrsC4.final_pred_testsub[:,1]]))\n",
    "submission(\"Johnston_Memic_Blind3.csv\", np.column_stack([attrsC1.final_pred_blindsub[:,1],\n",
    "                                                         attrsC2.final_pred_blindsub[:,1],\n",
    "                                                         attrsC3.final_pred_blindsub[:,1],\n",
    "                                                         attrsC4.final_pred_blindsub[:,1]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting code taken from: http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n",
    "%run 'plot_learning_curve.py'\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "def plotFeatureRankings(classifier, grid_scores):\n",
    "    \"\"\" Plot number of features VS. cross-validation scores\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title('Classifier {}'.format(classifier))\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "    plt.plot(range(1, len(grid_scores) + 1), grid_scores)\n",
    "    plt.show()\n",
    "        \n",
    "def createRFEScores(model, modelName, i, X_train, Y_train, X_test, Y_test):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    rfecv = RFECV(model, scoring='roc_auc', verbose=2, n_jobs=-1)\n",
    "    rfecv.fit(X_train, Y_train[:,i])\n",
    "    rfecv.score(X_test, Y_test[:,i])\n",
    "    print('Model {} Number Features {}'.format(i, rfecv.n_features_))\n",
    "    print('Model {} Number Estimators {}'.format(i, rfecv.ranking_))\n",
    "    print('Model {} Scores {}'.format(i, rfecv.grid_scores_))\n",
    "    print('Model {} Support {}'.format(i, rfecv.support_))\n",
    "\n",
    "    np.save('{}_class{}_ranking.npy'.format(modelName, i+1), rfecv.ranking_)\n",
    "    np.save('{}_class{}_scores.npy'.format(modelName, i+1), rfecv.grid_scores_)\n",
    "\n",
    "        \n",
    "# Set to True to run the RFE (time consuming)\n",
    "# Set to false to display pre-calculated results\n",
    "runRFE = True\n",
    "\n",
    "if runRFE:\n",
    "    \n",
    "    createRFEScores(attrsC1.final_model, 'final', 0, attrsC1.X_train, attrsC1.Y_train, attrsC1.X_test, attrsC1.Y_test)\n",
    "    createRFEScores(attrsC2.final_model, 'final', 1, attrsC2.X_train, attrsC2.Y_train, attrsC2.X_test, attrsC2.Y_test)\n",
    "    createRFEScores(attrsC3.final_model, 'final', 2, attrsC3.X_train, attrsC3.Y_train, attrsC3.X_test, attrsC3.Y_test)\n",
    "    createRFEScores(attrsC4.final_model, 'final', 3, attrsC4.X_train, attrsC4.Y_train, attrsC4.X_test, attrsC4.Y_test)\n",
    "    #createRFEScores(svc_model, 'svc', X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "else:\n",
    "    for i in range(4):\n",
    "        classifier = i+1\n",
    "        ranking = np.load('final_class{}_ranking.npy'.format(classifier))\n",
    "        grid_scores = np.load('final_class{}_scores.npy'.format(classifier))\n",
    "        \n",
    "        plotFeatureRankings(classifier, grid_scores)\n",
    "        \n",
    "    print('Class 1: Best score: ', 158)\n",
    "    print('Class 2: Best score: ', 147)\n",
    "    print('Class 3: Best score: ', 153)\n",
    "    print('Class 4: Best score: ', 64)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Module created for script run in IPython\n",
    "---------------------------------------------------------------------------\n",
    "IndexError                                Traceback (most recent call last)\n",
    "<ipython-input-37-9f34b449be9e> in <module>()\n",
    "     36 if runRFE:\n",
    "     37 \n",
    "---> 38     createRFEScores(attrsC1.final_model, 'final', 0, attrsC1.X_train, attrsC1.Y_train, attrsC1.X_test, attrsC1.Y_test)\n",
    "     39     createRFEScores(attrsC2.final_model, 'final', 1, attrsC2.X_train, attrsC2.Y_train, attrsC2.X_test, attrsC2.Y_test)\n",
    "     40     createRFEScores(attrsC3.final_model, 'final', 2, attrsC3.X_train, attrsC3.Y_train, attrsC3.X_test, attrsC3.Y_test)\n",
    "\n",
    "<ipython-input-37-9f34b449be9e> in createRFEScores(model, modelName, i, X_train, Y_train, X_test, Y_test)\n",
    "     19 \n",
    "     20     rfecv = RFECV(model, scoring='roc_auc', verbose=2, n_jobs=-1)\n",
    "---> 21     rfecv.fit(X_train, Y_train[:,i])\n",
    "     22     rfecv.score(X_test, Y_test[:,i])\n",
    "     23     print('Model {} Number Features {}'.format(i, rfecv.n_features_))\n",
    "\n",
    "IndexError: too many indices for array"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
