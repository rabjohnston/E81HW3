{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# The Journey\n",
    "\n",
    "This section describes the decisions taken to get to our final solution\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Baseline\n",
    "\n",
    "This section is the code we were given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data (1).\n",
      "Run model\n",
      "Calc ROC\n",
      "Baseline AUC is:  {0: 0.99996212682662722, 1: 0.99993172956870668, 2: 0.99996736488783788, 3: 0.99986086891635195}\n"
     ]
    }
   ],
   "source": [
    "# requires sciket-learn 0.18\n",
    "# if required, conda update scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.grid_search import GridSearchCV   #Performing grid search\n",
    "\n",
    "\n",
    "def readFiles():\n",
    "    #Reading files\n",
    "    X = pd.read_csv(\"trainingData.txt\",sep='\\t',header=None)\n",
    "    Y = pd.read_csv(\"trainingTruth.txt\",sep='\\t',header=None)\n",
    "    Y = np.array(Y).ravel()\n",
    "    \n",
    "    return (X,Y)\n",
    "\n",
    "\n",
    "def preprocessData1( X, Y ):\n",
    "    print('Preprocessing data (1).')\n",
    "    \n",
    "    # Replace NAs with 0\n",
    "    X = X.fillna(0) \n",
    "    \n",
    "    return (X,Y)\n",
    "\n",
    "\n",
    "def runModel1(X,Y):\n",
    "    print('Run model')\n",
    "    \n",
    "    clf = OneVsRestClassifier(RandomForestClassifier(n_estimators = 10,random_state=25))\n",
    "    clf.fit(X,Y)\n",
    "    Y_predict = clf.predict_proba(X)\n",
    "    \n",
    "    return Y_predict, clf\n",
    "\n",
    "\n",
    "def calculateROC(Y, Y_predict):\n",
    "    print('Calc ROC')\n",
    "    # Binarize the output\n",
    "    y_bin = label_binarize(Y, classes=[1, 2, 3,4])\n",
    "\n",
    "    #Calculate AUC\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(4):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], Y_predict[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "def createSubmission(clf, preprocessData=preprocessData1):\n",
    "    #Create submission\n",
    "    Xtest = pd.read_csv(\"testData.txt\",sep=\"\\t\",header=None)\n",
    "    \n",
    "    (Xtest) = preprocessData(Xtest)\n",
    "    y_final_prob = clf.predict_proba(Xtest)\n",
    "    y_final_label = clf.predict(Xtest)\n",
    "\n",
    "    sample = pd.DataFrame(np.hstack([y_final_prob.round(5),y_final_label.reshape(y_final_prob.shape[0],1)]))\n",
    "    sample.columns = [\"prob1\",\"prob2\",\"prob3\",\"prob4\",\"label\"]\n",
    "    sample.label = sample.label.astype(int)\n",
    "    \n",
    "    #Submit this file to dropbox\n",
    "    sample.to_csv(\"Johnston_Memic.csv\",sep=\"\\t\" ,index=False,header=None)\n",
    "    \n",
    "\n",
    "# Read the files in.   \n",
    "(X,Y) = readFiles()\n",
    "\n",
    "\n",
    "# Clean up the data\n",
    "(X,Y) = preprocessData1(X,Y)\n",
    "\n",
    "# Why does this not work?\n",
    "X.describe()\n",
    "\n",
    "# Run the model\n",
    "Y_predict, clf = runModel1(X,Y)\n",
    "\n",
    "baselineAUC = calculateROC(Y, Y_predict)\n",
    "\n",
    "print('Baseline AUC is: ', baselineAUC)\n",
    "\n",
    "#createSubmission(clf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing NAs\n",
    "\n",
    "First we analyse the prevalance on NAs in our features. For each feature, we calculate the frequency of NAs. This will help determine whether we think the feature is worth keeping as too many NAs indicates that the feature is not giving us enough information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of NAs in one column:  81\n",
      "Minimum number of NAs in one column:  40\n",
      "Maximum number of NAs in one row:  7\n",
      "Minimum number of NAs in one row:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rob/anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>324</th>\n",
       "      <th>325</th>\n",
       "      <th>326</th>\n",
       "      <th>327</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17321.000000</td>\n",
       "      <td>17325.000000</td>\n",
       "      <td>17312.000000</td>\n",
       "      <td>17322.000000</td>\n",
       "      <td>17324.000000</td>\n",
       "      <td>17324.000000</td>\n",
       "      <td>17317.000000</td>\n",
       "      <td>17333.000000</td>\n",
       "      <td>17326.000000</td>\n",
       "      <td>17297.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17321.000000</td>\n",
       "      <td>17311.000000</td>\n",
       "      <td>17331.000000</td>\n",
       "      <td>17316.000000</td>\n",
       "      <td>17314.000000</td>\n",
       "      <td>17312.000000</td>\n",
       "      <td>17310.000000</td>\n",
       "      <td>17314.000000</td>\n",
       "      <td>17319.000000</td>\n",
       "      <td>17334.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.264572</td>\n",
       "      <td>0.456596</td>\n",
       "      <td>0.435167</td>\n",
       "      <td>0.263299</td>\n",
       "      <td>0.496509</td>\n",
       "      <td>0.356921</td>\n",
       "      <td>0.362990</td>\n",
       "      <td>0.275144</td>\n",
       "      <td>0.423023</td>\n",
       "      <td>0.454524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448383</td>\n",
       "      <td>0.481281</td>\n",
       "      <td>0.277807</td>\n",
       "      <td>0.333366</td>\n",
       "      <td>0.474403</td>\n",
       "      <td>0.273570</td>\n",
       "      <td>0.447165</td>\n",
       "      <td>0.487169</td>\n",
       "      <td>0.267626</td>\n",
       "      <td>0.389999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.455943</td>\n",
       "      <td>0.513085</td>\n",
       "      <td>0.509448</td>\n",
       "      <td>0.452074</td>\n",
       "      <td>0.513279</td>\n",
       "      <td>0.495707</td>\n",
       "      <td>0.498107</td>\n",
       "      <td>0.463826</td>\n",
       "      <td>0.503520</td>\n",
       "      <td>0.513399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512189</td>\n",
       "      <td>0.520883</td>\n",
       "      <td>0.460411</td>\n",
       "      <td>0.485206</td>\n",
       "      <td>0.518349</td>\n",
       "      <td>0.460108</td>\n",
       "      <td>0.513640</td>\n",
       "      <td>0.512102</td>\n",
       "      <td>0.456374</td>\n",
       "      <td>0.503755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.560800</td>\n",
       "      <td>-1.506400</td>\n",
       "      <td>-1.399000</td>\n",
       "      <td>-1.488200</td>\n",
       "      <td>-1.442100</td>\n",
       "      <td>-1.306400</td>\n",
       "      <td>-1.884400</td>\n",
       "      <td>-1.721200</td>\n",
       "      <td>-1.444100</td>\n",
       "      <td>-1.578400</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.448600</td>\n",
       "      <td>-1.398600</td>\n",
       "      <td>-1.570100</td>\n",
       "      <td>-1.847300</td>\n",
       "      <td>-1.626700</td>\n",
       "      <td>-1.865800</td>\n",
       "      <td>-1.403600</td>\n",
       "      <td>-1.628900</td>\n",
       "      <td>-1.696800</td>\n",
       "      <td>-1.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.054600</td>\n",
       "      <td>2.519100</td>\n",
       "      <td>2.413700</td>\n",
       "      <td>2.129900</td>\n",
       "      <td>2.335800</td>\n",
       "      <td>2.251800</td>\n",
       "      <td>2.335600</td>\n",
       "      <td>2.086000</td>\n",
       "      <td>2.452100</td>\n",
       "      <td>2.486900</td>\n",
       "      <td>...</td>\n",
       "      <td>2.433600</td>\n",
       "      <td>2.372700</td>\n",
       "      <td>2.028400</td>\n",
       "      <td>2.522400</td>\n",
       "      <td>2.303300</td>\n",
       "      <td>2.020800</td>\n",
       "      <td>2.578200</td>\n",
       "      <td>2.407200</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>2.387100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  17321.000000  17325.000000  17312.000000  17322.000000  17324.000000   \n",
       "mean       0.264572      0.456596      0.435167      0.263299      0.496509   \n",
       "std        0.455943      0.513085      0.509448      0.452074      0.513279   \n",
       "min       -1.560800     -1.506400     -1.399000     -1.488200     -1.442100   \n",
       "25%             NaN           NaN           NaN           NaN           NaN   \n",
       "50%             NaN           NaN           NaN           NaN           NaN   \n",
       "75%             NaN           NaN           NaN           NaN           NaN   \n",
       "max        2.054600      2.519100      2.413700      2.129900      2.335800   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  17324.000000  17317.000000  17333.000000  17326.000000  17297.000000   \n",
       "mean       0.356921      0.362990      0.275144      0.423023      0.454524   \n",
       "std        0.495707      0.498107      0.463826      0.503520      0.513399   \n",
       "min       -1.306400     -1.884400     -1.721200     -1.444100     -1.578400   \n",
       "25%             NaN           NaN           NaN           NaN           NaN   \n",
       "50%             NaN           NaN           NaN           NaN           NaN   \n",
       "75%             NaN           NaN           NaN           NaN           NaN   \n",
       "max        2.251800      2.335600      2.086000      2.452100      2.486900   \n",
       "\n",
       "           ...                324           325           326           327  \\\n",
       "count      ...       17321.000000  17311.000000  17331.000000  17316.000000   \n",
       "mean       ...           0.448383      0.481281      0.277807      0.333366   \n",
       "std        ...           0.512189      0.520883      0.460411      0.485206   \n",
       "min        ...          -1.448600     -1.398600     -1.570100     -1.847300   \n",
       "25%        ...                NaN           NaN           NaN           NaN   \n",
       "50%        ...                NaN           NaN           NaN           NaN   \n",
       "75%        ...                NaN           NaN           NaN           NaN   \n",
       "max        ...           2.433600      2.372700      2.028400      2.522400   \n",
       "\n",
       "                328           329           330           331           332  \\\n",
       "count  17314.000000  17312.000000  17310.000000  17314.000000  17319.000000   \n",
       "mean       0.474403      0.273570      0.447165      0.487169      0.267626   \n",
       "std        0.518349      0.460108      0.513640      0.512102      0.456374   \n",
       "min       -1.626700     -1.865800     -1.403600     -1.628900     -1.696800   \n",
       "25%             NaN           NaN           NaN           NaN           NaN   \n",
       "50%             NaN           NaN           NaN           NaN           NaN   \n",
       "75%             NaN           NaN           NaN           NaN           NaN   \n",
       "max        2.303300      2.020800      2.578200      2.407200      2.070000   \n",
       "\n",
       "                333  \n",
       "count  17334.000000  \n",
       "mean       0.389999  \n",
       "std        0.503755  \n",
       "min       -1.466600  \n",
       "25%             NaN  \n",
       "50%             NaN  \n",
       "75%             NaN  \n",
       "max        2.387100  \n",
       "\n",
       "[8 rows x 334 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import itemfreq\n",
    "\n",
    "# Read the files in.   \n",
    "(X,Y) = readFiles()\n",
    "\n",
    "sums = {}\n",
    "\n",
    "total = X.shape[0]\n",
    "\n",
    "for col in X.columns:\n",
    "    # Count the NAs\n",
    "    sums[col] = total - X[col].count()\n",
    "    \n",
    "# Do something more clever here? Plot a distribution?\n",
    "#print(sums)\n",
    "print('Maximum number of NAs in one column: ', max(sums.values()))\n",
    "print('Minimum number of NAs in one column: ', min(sums.values()))\n",
    "\n",
    "# Check the rows to see if there are any rows with excessive NAs\n",
    "rowSums = X.isnull().sum(axis=1).tolist()\n",
    "print('Maximum number of NAs in one row: ', max(rowSums))\n",
    "print('Minimum number of NAs in one row: ', min(rowSums))\n",
    "\n",
    "X.describe()\n",
    "\n",
    "# Histogram of each variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of truth values.\n",
      "Frequencies:   1 :  0.326101968006 %\n",
      "Frequencies:   2 :  0.224018874439 %\n",
      "Frequencies:   3 :  0.300207158476 %\n",
      "Frequencies:   4 :  0.149671999079 %\n"
     ]
    }
   ],
   "source": [
    "# What's the distribution of outcomes?\n",
    "print('\\nDistribution of truth values.')\n",
    "itemFrequencies = itemfreq(Y)\n",
    "for freq, count in itemFrequencies:\n",
    "    print('Frequencies:  ', freq, ': ', count/total, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAs Replaced with Mean\n",
    "We first looked at the treatment of nulls. The first step is, instead of replacing NAs with 0, replace them with the mean of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "preprocessData3() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6972e4e3b769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Clean up the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessData3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Run the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: preprocessData3() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def preprocessData3( X ):\n",
    "    print('Preprocessing data (3).')\n",
    "\n",
    "    # Q: Normalise data for SVMs - what about decision trees?\n",
    "    \n",
    "\n",
    "    #Rewrite this from the HW ipython book\n",
    "    # Replace any NaN in X with the mean of the column\n",
    "    # Replacing with the mean gives a better score\n",
    "    xMean = []\n",
    "    for col in X.columns:\n",
    "        xMean = X[col].mean()\n",
    "        #print(col, ' ', xMean)\n",
    "        X.loc[X[col].isnull(), col] = xMean\n",
    "    \n",
    "    return (X)\n",
    "\n",
    "\n",
    "# Read the files in.   \n",
    "(X,Y) = readFiles()\n",
    "\n",
    "\n",
    "# Clean up the data\n",
    "(X,Y) = preprocessData3(X,Y)\n",
    "\n",
    "# Run the model\n",
    "Y_predict, clf = runModel1(X,Y)\n",
    "\n",
    "meanNAAUC = calculateROC(Y, Y_predict)\n",
    "\n",
    "print('Baseline AUC is: ', baselineAUC)\n",
    "print('Mean NA AUC is: ', meanNAAUC)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Submission\n",
    "\n",
    "Our first submission on Wednesday was a basic RFC. The intention was to understand the process of sumbitting a file for the homework and to see just how bad a classifier this was!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data (3).\n",
      "Baseline AUC is:  {0: 0.99996212682662722, 1: 0.99993172956870668, 2: 0.99996736488783788, 3: 0.99986086891635195}\n",
      "Wednesday AUC is:  {0: 0.9999989151110075, 1: 1.0, 2: 0.9999937267449213, 3: 1.0}\n"
     ]
    }
   ],
   "source": [
    "# This takes 86 min to run. Set to True if you want to run it, otherwise\n",
    "# the results will be taken from a previous run. The purpose of this was to run\n",
    "# a Grid Search to find best parameters for a random forest classifier.\n",
    "runLongRunningTest = False\n",
    "\n",
    "def runModelWedSubmission(X,Y):\n",
    "    print('Run model')\n",
    "    \n",
    "    model_to_set = OneVsRestClassifier(RandomForestClassifier())\n",
    "\n",
    "    param_test1 = {'estimator__n_estimators':[10,20,30,40,50], 'estimator__max_depth':[3,6,8,12,24,32], \n",
    "               'estimator__min_samples_split':[2,4,6],'estimator__min_samples_leaf':[1,2,4]}\n",
    "    \n",
    "        \n",
    "    gsearch1 = GridSearchCV(estimator = model_to_set, \n",
    "                        param_grid = param_test1,n_jobs=8,iid=False, cv=5,verbose=2)\n",
    "    gsearch1.fit(X,Y)\n",
    "\n",
    "    Y_predict = gsearch1.predict_proba(X)\n",
    "    \n",
    "    print('Best Params: ', gsearch1.best_params_)\n",
    "    print( 'Best Score: ', gsearch1.best_score_)\n",
    "\n",
    "    #clf = OneVsRestClassifier(RandomForestClassifier(n_estimators = 10,random_state=25))\n",
    "    #clf.fit(X,Y)\n",
    "    #Y_predict = clf.predict_proba(X)\n",
    "    \n",
    "    return Y_predict, clf\n",
    "\n",
    "\n",
    "# Read the files in.   \n",
    "(X,Y) = readFiles()\n",
    "\n",
    "\n",
    "# Clean up the data\n",
    "(X,Y) = preprocessData3(X,Y)\n",
    "\n",
    "\n",
    "\n",
    "if runLongRunningTest:\n",
    "    # Run the model\n",
    "    Y_predict, clf = runModelWedSubmission(X,Y)\n",
    "\n",
    "    wedSubmissionAAUC = calculateROC(Y, Y_predict)\n",
    "    createSubmission(clf)\n",
    "else:\n",
    "    # Results from previous run:\n",
    "    #  [Parallel(n_jobs=8)]: Done 1350 out of 1350 | elapsed: 89.6min finished\n",
    "    # Best Params:  {'estimator__max_depth': 32, 'estimator__min_samples_split': 4, 'estimator__n_estimators': 50, 'estimator__min_samples_leaf': 4}\n",
    "    # Best Score:  0.6728624493424956\n",
    "    wedSubmissionAAUC =  {0: 0.99999891511100747, 1: 1.0, 2: 0.99999372674492126, 3: 1.0}\n",
    "\n",
    "\n",
    "print('Baseline AUC is: ', baselineAUC)\n",
    "print('Wednesday AUC is: ', wedSubmissionAAUC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thursday Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data (3).\n",
      "Run model\n",
      "Calc ROC\n",
      "Preprocessing data (3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 334 features per sample; expecting 12",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-373915e7d9a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mthurSubmissionAAUC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculateROC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mcreateSubmission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocessData3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-73f538b997b9>\u001b[0m in \u001b[0;36mcreateSubmission\u001b[0;34m(clf, preprocessData)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0my_final_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0my_final_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rob/anaconda/lib/python3.5/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;31m# Y[i, j] gives the probability that sample i has the label j.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# In the multi-label case, these are not disjoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rob/anaconda/lib/python3.5/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;31m# Y[i, j] gives the probability that sample i has the label j.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# In the multi-label case, these are not disjoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rob/anaconda/lib/python3.5/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0mcalculate_ovr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ovr\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcalculate_ovr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rob/anaconda/lib/python3.5/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_predict_proba_lr\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mmulticlass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mhandled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnormalizing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mover\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \"\"\"\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rob/anaconda/lib/python3.5/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 317\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 334 features per sample; expecting 12"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def runModelThurSubmission(X,Y):\n",
    "    print('Run model')\n",
    "    \n",
    "    # This is taken from the section notebook. The only modification is for the RFC which we have already\n",
    "    # run a hyperparameter search on.\n",
    "    \n",
    "    #Build Model1 - Level 0\n",
    "    Model1 = OneVsRestClassifier(RandomForestClassifier(\n",
    "            n_estimators=50, \n",
    "            max_depth=32, \n",
    "            min_samples_split=4, \n",
    "            min_samples_leaf=4))\n",
    "    Model1.fit(X,Y)\n",
    "\n",
    "    #Predict on X_train, X_test\n",
    "    Model1_pred_test = Model1.predict_proba(X)\n",
    "    #Model1_pred_train = Model1.predict_proba(X_train)\n",
    "\n",
    "    #Build Model3 - Level 0\n",
    "    Model3 = OneVsRestClassifier(QuadraticDiscriminantAnalysis())\n",
    "    Model3.fit(X,Y)\n",
    "    Model3_pred_test = Model3.predict_proba(X)\n",
    "    #Model3_pred_train = Model3.predict_proba(X_train)\n",
    "\n",
    "    #Build Model5 - Level 0\n",
    "    Model5 = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=15, weights='distance'))\n",
    "    Model5.fit(X,Y)\n",
    "    Model5_pred_test = Model5.predict_proba(X)\n",
    "    #Model5_pred_train = Model5.predict_proba(X_train)\n",
    "    \n",
    "    #Model 4 - Level 1 \n",
    "    #Creating training attributes for Model4 (based on Model1, Model3, Model5 )\n",
    "    FeaturesTest1 = np.hstack([Model1_pred_test,Model3_pred_test,Model5_pred_test])  \n",
    "    Model4 = OneVsRestClassifier(LogisticRegression(random_state=49))\n",
    "    Model4.fit(FeaturesTest1,Y)\n",
    "\n",
    "    #Creating test attributes for Model3 (based on Model1 and Model2)\n",
    "    #FeaturesTest1 = np.hstack([Model1_pred_test,Model3_pred_test,Model5_pred_test])\n",
    "\n",
    "    #Final predictions\n",
    "    final_pred = Model4.predict_proba(FeaturesTest1)\n",
    "\n",
    "    #AUC\n",
    "    #fpr, tpr, thresholds = roc_curve(Y, final_pred[:, 1])\n",
    "    #roc_auc = auc(fpr, tpr)\n",
    "    #print(\"AUC with Stacking: \" , roc_auc)\n",
    "    #Minor improvement with stacking over stand alone models\n",
    "    \n",
    "    return final_pred, Model4\n",
    "\n",
    "    \n",
    "# Read the files in.   \n",
    "(X,Y) = readFiles()\n",
    "\n",
    "\n",
    "# Clean up the data\n",
    "(X,Y) = preprocessData3(X,Y)\n",
    "\n",
    "# Run the model\n",
    "Y_predict, clf = runModelThurSubmission(X,Y)\n",
    "\n",
    "thurSubmissionAAUC = calculateROC(Y, Y_predict)\n",
    "\n",
    "createSubmission(clf,preprocessData3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data (3).\n"
     ]
    }
   ],
   "source": [
    "createSubmission(clf,preprocessData3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# The Final Solution\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "NB: When you run the sample (before upgrading) these are the values it produces: {0: 0.95755745500532141, 1: 0.94345356758244103, 2: 0.95754489510952012, 3: 0.935902875654121}"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
