{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# The Journey\n",
    "\n",
    "This section describes the decisions taken to get to our final solution\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Baseline\n",
    "\n",
    "This section is the code we were given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haris/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/haris/anaconda/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data (1).\n",
      "Run model\n",
      "Calc ROC\n",
      "Baseline AUC is:  {0: 0.99996212682662722, 1: 0.99993172956870668, 2: 0.99996736488783788, 3: 0.99986086891635195}\n"
     ]
    }
   ],
   "source": [
    "# requires sciket-learn 0.18\n",
    "# if required, conda update scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.grid_search import GridSearchCV   #Performing grid search\n",
    "\n",
    "\n",
    "def readFiles():\n",
    "    #Reading files\n",
    "    X = pd.read_csv(\"trainingData.txt\",sep='\\t',header=None)\n",
    "    Y = pd.read_csv(\"trainingTruth.txt\",sep='\\t',header=None)\n",
    "    Y = np.array(Y).ravel()\n",
    "    \n",
    "    return (X,Y)\n",
    "\n",
    "\n",
    "def preprocessFeatures1( X ):\n",
    "    print('Preprocessing data (1).')\n",
    "    \n",
    "    # Replace NAs with 0\n",
    "    X = X.fillna(0) \n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def runModel1(X,Y):\n",
    "    print('Run model')\n",
    "    \n",
    "    clf = OneVsRestClassifier(RandomForestClassifier(n_estimators = 10,random_state=25))\n",
    "    clf.fit(X,Y)\n",
    "    Y_predict = clf.predict_proba(X)\n",
    "    \n",
    "    return Y_predict, clf\n",
    "\n",
    "\n",
    "def calculateROC(Y, Y_predict):\n",
    "    print('Calc ROC')\n",
    "    # Binarize the output\n",
    "    y_bin = label_binarize(Y, classes=[1, 2, 3,4])\n",
    "\n",
    "    #Calculate AUC\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(4):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], Y_predict[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "def createSubmission(clf, preprocessData=preprocessFeatures1):\n",
    "    #Create submission\n",
    "    Xtest = pd.read_csv(\"testData.txt\",sep=\"\\t\",header=None)\n",
    "    \n",
    "    (Xtest) = preprocessData(Xtest)\n",
    "    y_final_prob = clf.predict_proba(Xtest)\n",
    "    y_final_label = clf.predict(Xtest)\n",
    "\n",
    "    sample = pd.DataFrame(np.hstack([y_final_prob.round(5),y_final_label.reshape(y_final_prob.shape[0],1)]))\n",
    "    sample.columns = [\"prob1\",\"prob2\",\"prob3\",\"prob4\",\"label\"]\n",
    "    sample.label = sample.label.astype(int)\n",
    "    \n",
    "    #Submit this file to dropbox\n",
    "    sample.to_csv(\"Johnston_Memic.csv\",sep=\"\\t\" ,index=False,header=None)\n",
    "    \n",
    "\n",
    "# Read the files in.   \n",
    "(XOrig,YOrig) = readFiles()\n",
    "\n",
    "\n",
    "# Clean up the data\n",
    "X = preprocessFeatures1(XOrig)\n",
    "Y = YOrig\n",
    "\n",
    "# Run the model\n",
    "Y_predict, clf = runModel1(X,Y)\n",
    "\n",
    "baselineAUC = calculateROC(Y, Y_predict)\n",
    "\n",
    "print('Baseline AUC is: ', baselineAUC)\n",
    "\n",
    "#createSubmission(clf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing NAs\n",
    "\n",
    "First we analyse the prevalance on NAs in our features. For each feature, we calculate the frequency of NAs. This will help determine whether we think the feature is worth keeping as too many NAs indicates that the feature is not giving us enough information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of NAs in one column:  81\n",
      "Minimum number of NAs in one column:  40\n",
      "Maximum number of NAs in one row:  7\n",
      "Minimum number of NAs in one row:  0\n",
      "Number of rows with 3+ missing features 1747\n",
      "Number of rows with 2+ missing features 5264\n",
      "Number of rows with 1+ missing features 11619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haris/anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>324</th>\n",
       "      <th>325</th>\n",
       "      <th>326</th>\n",
       "      <th>327</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17321.000000</td>\n",
       "      <td>17325.000000</td>\n",
       "      <td>17312.000000</td>\n",
       "      <td>17322.000000</td>\n",
       "      <td>17324.000000</td>\n",
       "      <td>17324.000000</td>\n",
       "      <td>17317.000000</td>\n",
       "      <td>17333.000000</td>\n",
       "      <td>17326.000000</td>\n",
       "      <td>17297.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17321.000000</td>\n",
       "      <td>17311.000000</td>\n",
       "      <td>17331.000000</td>\n",
       "      <td>17316.000000</td>\n",
       "      <td>17314.000000</td>\n",
       "      <td>17312.000000</td>\n",
       "      <td>17310.000000</td>\n",
       "      <td>17314.000000</td>\n",
       "      <td>17319.000000</td>\n",
       "      <td>17334.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.264572</td>\n",
       "      <td>0.456596</td>\n",
       "      <td>0.435167</td>\n",
       "      <td>0.263299</td>\n",
       "      <td>0.496509</td>\n",
       "      <td>0.356921</td>\n",
       "      <td>0.362990</td>\n",
       "      <td>0.275144</td>\n",
       "      <td>0.423023</td>\n",
       "      <td>0.454524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448383</td>\n",
       "      <td>0.481281</td>\n",
       "      <td>0.277807</td>\n",
       "      <td>0.333366</td>\n",
       "      <td>0.474403</td>\n",
       "      <td>0.273570</td>\n",
       "      <td>0.447165</td>\n",
       "      <td>0.487169</td>\n",
       "      <td>0.267626</td>\n",
       "      <td>0.389999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.455943</td>\n",
       "      <td>0.513085</td>\n",
       "      <td>0.509448</td>\n",
       "      <td>0.452074</td>\n",
       "      <td>0.513279</td>\n",
       "      <td>0.495707</td>\n",
       "      <td>0.498107</td>\n",
       "      <td>0.463826</td>\n",
       "      <td>0.503520</td>\n",
       "      <td>0.513399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512189</td>\n",
       "      <td>0.520883</td>\n",
       "      <td>0.460411</td>\n",
       "      <td>0.485206</td>\n",
       "      <td>0.518349</td>\n",
       "      <td>0.460108</td>\n",
       "      <td>0.513640</td>\n",
       "      <td>0.512102</td>\n",
       "      <td>0.456374</td>\n",
       "      <td>0.503755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.560800</td>\n",
       "      <td>-1.506400</td>\n",
       "      <td>-1.399000</td>\n",
       "      <td>-1.488200</td>\n",
       "      <td>-1.442100</td>\n",
       "      <td>-1.306400</td>\n",
       "      <td>-1.884400</td>\n",
       "      <td>-1.721200</td>\n",
       "      <td>-1.444100</td>\n",
       "      <td>-1.578400</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.448600</td>\n",
       "      <td>-1.398600</td>\n",
       "      <td>-1.570100</td>\n",
       "      <td>-1.847300</td>\n",
       "      <td>-1.626700</td>\n",
       "      <td>-1.865800</td>\n",
       "      <td>-1.403600</td>\n",
       "      <td>-1.628900</td>\n",
       "      <td>-1.696800</td>\n",
       "      <td>-1.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.054600</td>\n",
       "      <td>2.519100</td>\n",
       "      <td>2.413700</td>\n",
       "      <td>2.129900</td>\n",
       "      <td>2.335800</td>\n",
       "      <td>2.251800</td>\n",
       "      <td>2.335600</td>\n",
       "      <td>2.086000</td>\n",
       "      <td>2.452100</td>\n",
       "      <td>2.486900</td>\n",
       "      <td>...</td>\n",
       "      <td>2.433600</td>\n",
       "      <td>2.372700</td>\n",
       "      <td>2.028400</td>\n",
       "      <td>2.522400</td>\n",
       "      <td>2.303300</td>\n",
       "      <td>2.020800</td>\n",
       "      <td>2.578200</td>\n",
       "      <td>2.407200</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>2.387100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  17321.000000  17325.000000  17312.000000  17322.000000  17324.000000   \n",
       "mean       0.264572      0.456596      0.435167      0.263299      0.496509   \n",
       "std        0.455943      0.513085      0.509448      0.452074      0.513279   \n",
       "min       -1.560800     -1.506400     -1.399000     -1.488200     -1.442100   \n",
       "25%             NaN           NaN           NaN           NaN           NaN   \n",
       "50%             NaN           NaN           NaN           NaN           NaN   \n",
       "75%             NaN           NaN           NaN           NaN           NaN   \n",
       "max        2.054600      2.519100      2.413700      2.129900      2.335800   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  17324.000000  17317.000000  17333.000000  17326.000000  17297.000000   \n",
       "mean       0.356921      0.362990      0.275144      0.423023      0.454524   \n",
       "std        0.495707      0.498107      0.463826      0.503520      0.513399   \n",
       "min       -1.306400     -1.884400     -1.721200     -1.444100     -1.578400   \n",
       "25%             NaN           NaN           NaN           NaN           NaN   \n",
       "50%             NaN           NaN           NaN           NaN           NaN   \n",
       "75%             NaN           NaN           NaN           NaN           NaN   \n",
       "max        2.251800      2.335600      2.086000      2.452100      2.486900   \n",
       "\n",
       "           ...                324           325           326           327  \\\n",
       "count      ...       17321.000000  17311.000000  17331.000000  17316.000000   \n",
       "mean       ...           0.448383      0.481281      0.277807      0.333366   \n",
       "std        ...           0.512189      0.520883      0.460411      0.485206   \n",
       "min        ...          -1.448600     -1.398600     -1.570100     -1.847300   \n",
       "25%        ...                NaN           NaN           NaN           NaN   \n",
       "50%        ...                NaN           NaN           NaN           NaN   \n",
       "75%        ...                NaN           NaN           NaN           NaN   \n",
       "max        ...           2.433600      2.372700      2.028400      2.522400   \n",
       "\n",
       "                328           329           330           331           332  \\\n",
       "count  17314.000000  17312.000000  17310.000000  17314.000000  17319.000000   \n",
       "mean       0.474403      0.273570      0.447165      0.487169      0.267626   \n",
       "std        0.518349      0.460108      0.513640      0.512102      0.456374   \n",
       "min       -1.626700     -1.865800     -1.403600     -1.628900     -1.696800   \n",
       "25%             NaN           NaN           NaN           NaN           NaN   \n",
       "50%             NaN           NaN           NaN           NaN           NaN   \n",
       "75%             NaN           NaN           NaN           NaN           NaN   \n",
       "max        2.303300      2.020800      2.578200      2.407200      2.070000   \n",
       "\n",
       "                333  \n",
       "count  17334.000000  \n",
       "mean       0.389999  \n",
       "std        0.503755  \n",
       "min       -1.466600  \n",
       "25%             NaN  \n",
       "50%             NaN  \n",
       "75%             NaN  \n",
       "max        2.387100  \n",
       "\n",
       "[8 rows x 334 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import itemfreq\n",
    "\n",
    "X = XOrig\n",
    "Y = YOrig\n",
    "\n",
    "sums = {}\n",
    "\n",
    "total = X.shape[0]\n",
    "\n",
    "for col in X.columns:\n",
    "    # Count the NAs\n",
    "    sums[col] = total - X[col].count()\n",
    "    \n",
    "# Do something more clever here? Plot a distribution?\n",
    "#print(sums)\n",
    "print('Maximum number of NAs in one column: ', max(sums.values()))\n",
    "print('Minimum number of NAs in one column: ', min(sums.values()))\n",
    "\n",
    "# Check the rows to see if there are any rows with excessive NAs\n",
    "rowSums = X.isnull().sum(axis=1).tolist()\n",
    "print('Maximum number of NAs in one row: ', max(rowSums))\n",
    "print('Minimum number of NAs in one row: ', min(rowSums))\n",
    "\n",
    "missining3plus = total - rowSums.count(0) - rowSums.count(1) - rowSums.count(2)\n",
    "print(\"Number of rows with 3+ missing features\", missining3plus)\n",
    "missining2plus = total - rowSums.count(0) - rowSums.count(1)\n",
    "print(\"Number of rows with 2+ missing features\", missining2plus)\n",
    "missining1plus = total - rowSums.count(0) \n",
    "print(\"Number of rows with 1+ missing features\", missining1plus)\n",
    "\n",
    "X.describe()\n",
    "\n",
    "# Histogram of each variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of truth values.\n",
      "Frequencies:   1 :  0.326101968006 %\n",
      "Frequencies:   2 :  0.224018874439 %\n",
      "Frequencies:   3 :  0.300207158476 %\n",
      "Frequencies:   4 :  0.149671999079 %\n"
     ]
    }
   ],
   "source": [
    "# What's the distribution of outcomes?\n",
    "print('\\nDistribution of truth values.')\n",
    "itemFrequencies = itemfreq(Y)\n",
    "for freq, count in itemFrequencies:\n",
    "    print('Frequencies:  ', freq, ': ', count/total, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAs Replaced with Mean\n",
    "We first looked at the treatment of nulls. The first step is, instead of replacing NAs with 0, replace them with the mean of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data (3).\n",
      "Run model\n",
      "Calc ROC\n",
      "Baseline AUC is:  {0: 0.99996212682662722, 1: 0.99993172956870668, 2: 0.99996736488783788, 3: 0.99986086891635195}\n",
      "Mean NA AUC is:  {0: 0.99998479648620131, 1: 0.99993036758884135, 2: 0.99994417906316257, 3: 0.99988691290227649}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def preprocessFeatures3( X ):\n",
    "    print('Preprocessing data (3).')\n",
    "\n",
    "    # Q: Normalise data for SVMs - what about decision trees?\n",
    "    \n",
    "\n",
    "    #Rewrite this from the HW ipython book\n",
    "    # Replace any NaN in X with the mean of the column\n",
    "    # Replacing with the mean gives a better score\n",
    "    xMean = []\n",
    "    for col in X.columns:\n",
    "        xMean = X[col].mean()\n",
    "        #print(col, ' ', xMean)\n",
    "        X.loc[X[col].isnull(), col] = xMean\n",
    "    \n",
    "    return (X)\n",
    "\n",
    "\n",
    "# Clean up the data\n",
    "X = preprocessFeatures3(XOrig)\n",
    "Y = YOrig\n",
    "\n",
    "# Run the model\n",
    "Y_predict, clf = runModel1(X,Y)\n",
    "\n",
    "meanNAAUC = calculateROC(Y, Y_predict)\n",
    "\n",
    "print('Baseline AUC is: ', baselineAUC)\n",
    "print('Mean NA AUC is: ', meanNAAUC)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Run a RFC to see feature importance?\n",
    "Plot histograms of all features?\n",
    "\n",
    "See other notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Submission\n",
    "\n",
    "Our first submission on Wednesday was a basic RFC. The intention was to understand the process of sumbitting a file for the homework and to see just how bad a classifier this was!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data (3).\n",
      "Baseline AUC is:  {0: 0.99996212682662722, 1: 0.99993172956870668, 2: 0.99996736488783788, 3: 0.99986086891635195}\n",
      "Wednesday AUC is:  {0: 0.9999989151110075, 1: 1.0, 2: 0.9999937267449213, 3: 1.0}\n"
     ]
    }
   ],
   "source": [
    "# This takes 86 min to run. Set to True if you want to run it, otherwise\n",
    "# the results will be taken from a previous run. The purpose of this was to run\n",
    "# a Grid Search to find best parameters for a random forest classifier.\n",
    "runLongRunningTest = False\n",
    "\n",
    "def runModelWedSubmission(X,Y):\n",
    "    print('Run model')\n",
    "    \n",
    "    model_to_set = OneVsRestClassifier(RandomForestClassifier())\n",
    "\n",
    "    param_test1 = {'estimator__n_estimators':[10,20,30,40,50], 'estimator__max_depth':[3,6,8,12,24,32], \n",
    "               'estimator__min_samples_split':[2,4,6],'estimator__min_samples_leaf':[1,2,4]}\n",
    "    \n",
    "        \n",
    "    gsearch1 = GridSearchCV(estimator = model_to_set, \n",
    "                        param_grid = param_test1,n_jobs=8,iid=False, cv=5,verbose=2)\n",
    "    gsearch1.fit(X,Y)\n",
    "\n",
    "    Y_predict = gsearch1.predict_proba(X)\n",
    "    \n",
    "    print('Best Params: ', gsearch1.best_params_)\n",
    "    print( 'Best Score: ', gsearch1.best_score_)\n",
    "\n",
    "    #clf = OneVsRestClassifier(RandomForestClassifier(n_estimators = 10,random_state=25))\n",
    "    #clf.fit(X,Y)\n",
    "    #Y_predict = clf.predict_proba(X)\n",
    "    \n",
    "    return Y_predict, clf\n",
    "\n",
    "\n",
    "# Clean up the data\n",
    "X = preprocessFeatures3(XOrig)\n",
    "\n",
    "\n",
    "\n",
    "if runLongRunningTest:\n",
    "    # Run the model\n",
    "    Y_predict, clf = runModelWedSubmission(X,Y)\n",
    "\n",
    "    wedSubmissionAAUC = calculateROC(Y, Y_predict)\n",
    "    createSubmission(clf)\n",
    "else:\n",
    "    # Results from previous run:\n",
    "    #  [Parallel(n_jobs=8)]: Done 1350 out of 1350 | elapsed: 89.6min finished\n",
    "    # Best Params:  {'estimator__max_depth': 32, 'estimator__min_samples_split': 4, 'estimator__n_estimators': 50, 'estimator__min_samples_leaf': 4}\n",
    "    # Best Score:  0.6728624493424956\n",
    "    wedSubmissionAAUC =  {0: 0.99999891511100747, 1: 1.0, 2: 0.99999372674492126, 3: 1.0}\n",
    "\n",
    "\n",
    "print('Baseline AUC is: ', baselineAUC)\n",
    "print('Wednesday AUC is: ', wedSubmissionAAUC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thursday Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data (3).\n",
      "Run model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def runModelThurSubmission(X,Y):\n",
    "    print('Run model')\n",
    "    \n",
    "    # This is taken from the section notebook. The only modification is for the RFC which we have already\n",
    "    # run a hyperparameter search on.\n",
    "    \n",
    "    #Build Model1 - Level 0\n",
    "    Model1 = OneVsRestClassifier(RandomForestClassifier(\n",
    "            n_estimators=50, \n",
    "            max_depth=32, \n",
    "            min_samples_split=4, \n",
    "            min_samples_leaf=4))\n",
    "    Model1.fit(X,Y)\n",
    "\n",
    "    #Predict on X_train, X_test\n",
    "    Model1_pred_test = Model1.predict_proba(X)\n",
    "    #Model1_pred_train = Model1.predict_proba(X_train)\n",
    "\n",
    "    #Build Model3 - Level 0\n",
    "    Model3 = OneVsRestClassifier(QuadraticDiscriminantAnalysis())\n",
    "    Model3.fit(X,Y)\n",
    "    Model3_pred_test = Model3.predict_proba(X)\n",
    "    #Model3_pred_train = Model3.predict_proba(X_train)\n",
    "\n",
    "    #Build Model5 - Level 0\n",
    "    Model5 = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=15, weights='distance'))\n",
    "    Model5.fit(X,Y)\n",
    "    Model5_pred_test = Model5.predict_proba(X)\n",
    "    #Model5_pred_train = Model5.predict_proba(X_train)\n",
    "    \n",
    "    #Model 4 - Level 1 \n",
    "    #Creating training attributes for Model4 (based on Model1, Model3, Model5 )\n",
    "    FeaturesTest1 = np.hstack([Model1_pred_test,Model3_pred_test,Model5_pred_test])  \n",
    "    Model4 = OneVsRestClassifier(LogisticRegression(random_state=49))\n",
    "    Model4.fit(FeaturesTest1,Y)\n",
    "\n",
    "    #Creating test attributes for Model3 (based on Model1 and Model2)\n",
    "    #FeaturesTest1 = np.hstack([Model1_pred_test,Model3_pred_test,Model5_pred_test])\n",
    "\n",
    "    #Final predictions\n",
    "    final_pred = Model4.predict_proba(FeaturesTest1)\n",
    "\n",
    "    #AUC\n",
    "    #fpr, tpr, thresholds = roc_curve(Y, final_pred[:, 1])\n",
    "    #roc_auc = auc(fpr, tpr)\n",
    "    #print(\"AUC with Stacking: \" , roc_auc)\n",
    "    #Minor improvement with stacking over stand alone models\n",
    "    \n",
    "    return final_pred, Model4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Clean up the data\n",
    "X = preprocessFeatures3(XOrig)\n",
    "Y = YOrig\n",
    "\n",
    "# Run the model\n",
    "Y_predict, clf = runModelThurSubmission(X,Y)\n",
    "\n",
    "thurSubmissionAAUC = calculateROC(Y, Y_predict)\n",
    "\n",
    "createSubmission(clf,preprocessData3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sunday Submission\n",
    "\n",
    "Simply using Thursdays submission but removing some non-important features (TBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rank_to_dict(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x, 2), ranks)\n",
    "    return dict(zip(names, ranks ))\n",
    "\n",
    "\n",
    "\n",
    "def dropEstimators(X,Y):\n",
    "    \n",
    "    for i in range()\n",
    "        clf = OneVsRestClassifier(RandomForestClassifier(n_estimators = 50,\n",
    "                                                         max_depth = 32,\n",
    "                                                         min_samples_split = 4,\n",
    "                                                         min_samples_leaf = 4,\n",
    "                                                         random_state=25))\n",
    "        clf.fit(X,Y)\n",
    "\n",
    "        for i in range(4):\n",
    "            print(clf.estimators_[i].feature_importances_)\n",
    "    \n",
    "    \n",
    "    \n",
    "def runModelSatSubmission(X,Y):\n",
    "    print('Run model')\n",
    "    \n",
    "    clf = OneVsRestClassifier(RandomForestClassifier(n_estimators = 50,\n",
    "                                                     max_depth = 32,\n",
    "                                                     min_samples_split = 4,\n",
    "                                                     min_samples_leaf = 4,\n",
    "                                                     random_state=25))\n",
    "    clf.fit(X,Y)\n",
    "    Y_predict = clf.predict_proba(X)\n",
    "    \n",
    "    return Y_predict, clf\n",
    "\n",
    "#Split into training and test set - where the latter is 15% of the total \n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.15, random_state=10) \n",
    "#print (X.shape, X_train.shape, X_test.shape)\n",
    "\n",
    "# Clean up the data\n",
    "X = preprocessFeatures3(XOrig)\n",
    "Y = YOrig\n",
    "\n",
    "X = dropEstimators(X,Y)\n",
    "#Y_predict, clf = runModelSatSubmission(X,Y)\n",
    "#satSubmissionAAUC = calculateROC(Y, Y_predict)\n",
    "#createSubmission(clf)\n",
    "\n",
    "\n",
    "#print('Baseline AUC is: ', baselineAUC)\n",
    "#print('Wednesday AUC is: ', satSubmissionAAUC)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "createSubmission(clf,preprocessData3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# The Final Solution\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "NB: When you run the sample (before upgrading) these are the values it produces: {0: 0.95755745500532141, 1: 0.94345356758244103, 2: 0.95754489510952012, 3: 0.935902875654121}"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
