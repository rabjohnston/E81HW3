{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# The Journey\n",
    "\n",
    "This section describes the decisions taken to get to our final solution\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Baseline\n",
    "\n",
    "This section is the code we were given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data.\n",
      "Run model\n",
      "Calc ROC\n",
      "{0: 0.99996212682662722, 1: 0.99993172956870668, 2: 0.99996736488783788, 3: 0.99986086891635195}\n"
     ]
    }
   ],
   "source": [
    "# requires sciket-learn 0.18\n",
    "# if required, conda update scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "def readFiles():\n",
    "    #Reading files\n",
    "    X = pd.read_csv(\"trainingData.txt\",sep='\\t',header=None)\n",
    "    Y = pd.read_csv(\"trainingTruth.txt\",sep='\\t',header=None)\n",
    "    Y = np.array(Y).ravel()\n",
    "    \n",
    "    return (X,Y)\n",
    "\n",
    "\n",
    "def preprocessData1( X, Y ):\n",
    "    print('Preprocessing data.')\n",
    "    \n",
    "    # Replace NAs with 0\n",
    "    X = X.fillna(0) \n",
    "    \n",
    "    return (X,Y)\n",
    "\n",
    "\n",
    "def runModel1(X,Y):\n",
    "    print('Run model')\n",
    "    \n",
    "    clf = OneVsRestClassifier(RandomForestClassifier(n_estimators = 10,random_state=25))\n",
    "    clf.fit(X,Y)\n",
    "    Y_predict = clf.predict_proba(X)\n",
    "    \n",
    "    return Y_predict, clf\n",
    "\n",
    "\n",
    "def calculateROC(Y, Y_predict):\n",
    "    print('Calc ROC')\n",
    "    # Binarize the output\n",
    "    y_bin = label_binarize(Y, classes=[1, 2, 3,4])\n",
    "\n",
    "    #Calculate AUC\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(4):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], Y_predict[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "def createSubmission(clf):\n",
    "    #Create submission\n",
    "    Xtest = pd.read_csv(\"testData.txt\",sep=\"\\t\",header=None)\n",
    "    y_final_prob = clf.predict_proba(Xtest)\n",
    "    y_final_label = clf.predict(Xtest)\n",
    "\n",
    "    sample = pd.DataFrame(np.hstack([y_final_prob.round(5),y_final_label.reshape(y_final_prob.shape[0],1)]))\n",
    "    sample.columns = [\"prob1\",\"prob2\",\"prob3\",\"prob4\",\"label\"]\n",
    "    sample.label = sample.label.astype(int)\n",
    "    \n",
    "    #Submit this file to dropbox\n",
    "    sample.to_csv(\"Johnston_Memic.csv\",sep=\"\\t\" ,index=False,header=None)\n",
    "    \n",
    "\n",
    "# Read the files in.   \n",
    "(X,Y) = readFiles()\n",
    "\n",
    "# Clean up the data\n",
    "(X,Y) = preprocessData1(X,Y)\n",
    "\n",
    "# Run the model\n",
    "Y_predict, clf = runModel1(X,Y)\n",
    "\n",
    "baselineAUC = calculateROC(Y, Y_predict)\n",
    "\n",
    "print('Baseline AUC is: ', baselineAUC)\n",
    "\n",
    "#createSubmission(clf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing NAs\n",
    "\n",
    "First we analyse the prevalance on NAs in our features. For each feature, we calculate the frequency of NAs. This will help determine whether we think the feature is worth keeping as too many NAs indicates that the feature is not giving us enough information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of NAs in one column:  81\n",
      "Minimum number of NAs in one column:  40\n",
      "Maximum number of NAs in one row:  7\n",
      "Minimum number of NAs in one row:  0\n"
     ]
    }
   ],
   "source": [
    "# Read the files in.   \n",
    "(X,Y) = readFiles()\n",
    "\n",
    "sums = {}\n",
    "\n",
    "total = X.shape[0]\n",
    "\n",
    "for col in X.columns:\n",
    "    # Count the NAs\n",
    "    sums[col] = total - X[col].count()\n",
    "    \n",
    "# Do something more clever here? Plot a distribution?\n",
    "#print(sums)\n",
    "print('Maximum number of NAs in one column: ', max(sums.values()))\n",
    "print('Minimum number of NAs in one column: ', min(sums.values()))\n",
    "\n",
    "# Check the rows to see if there are any rows with excessive NAs\n",
    "rowSums = X.isnull().sum(axis=1).tolist()\n",
    "print('Maximum number of NAs in one row: ', max(rowSums))\n",
    "print('Minimum number of NAs in one row: ', min(rowSums))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAs Replaced with Mean\n",
    "We first looked at the treatment of nulls. The first step is, instead of replacing NAs with 0, replace them with the mean of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data.\n",
      "Run model\n",
      "Calc ROC\n",
      "Baseline AUC is:  {0: 0.99996212682662722, 1: 0.99993172956870668, 2: 0.99996736488783788, 3: 0.99986086891635195}\n",
      "Mean NA AUC is:  {0: 0.99998479648620131, 1: 0.99993036758884135, 2: 0.99994417906316257, 3: 0.99988691290227649}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def preprocessData3( X, Y ):\n",
    "    print('Preprocessing data.')\n",
    "\n",
    "    # Q: Normalise data for SVMs - what about decision trees?\n",
    "    \n",
    "\n",
    "    #Rewrite this from the HW ipython book\n",
    "    # Replace any NaN in X with the mean of the column\n",
    "    # Replacing with the mean gives a better score\n",
    "    xMean = []\n",
    "    for col in X.columns:\n",
    "        xMean = X[col].mean()\n",
    "        #print(col, ' ', xMean)\n",
    "        X.loc[X[col].isnull(), col] = xMean\n",
    "    \n",
    "    return (X,Y)\n",
    "\n",
    "\n",
    "# Read the files in.   \n",
    "(X,Y) = readFiles()\n",
    "\n",
    "\n",
    "# Clean up the data\n",
    "(X,Y) = preprocessData3(X,Y)\n",
    "\n",
    "# Run the model\n",
    "Y_predict, clf = runModel1(X,Y)\n",
    "\n",
    "meanNAAUC = calculateROC(Y, Y_predict)\n",
    "\n",
    "print('Baseline AUC is: ', baselineAUC)\n",
    "print('Mean NA AUC is: ', meanNAAUC)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# The Final Solution\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "NB: When you run the sample (before upgrading) these are the values it produces: {0: 0.95755745500532141, 1: 0.94345356758244103, 2: 0.95754489510952012, 3: 0.935902875654121}"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
